{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847f8e5a",
   "metadata": {},
   "source": [
    "## 자동 미분과 선형 회귀 실습\n",
    "- 선형 회귀를 텐서플로우와 케라스를 통해 구현\n",
    "- https://wikidocs.net/111472"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c041d",
   "metadata": {},
   "source": [
    "### 자동미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf0f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2a516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "  y = w**2\n",
    "  z = 2*y + 5 #임의의 식\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f7a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "# tape_gradient()는 자동 미분 기능을 수행\n",
    "with tf.GradientTape() as tape:\n",
    "  z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abb66e",
   "metadata": {},
   "source": [
    "### 자동 미분을 이용한 선형 회귀 구현\n",
    "- 가중치 변수 w와 b를 선언\n",
    "- 학습될 값이므로 임의의 값인 4와 1로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c079213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습될 가중치 변수를 선언\n",
    "w = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d157bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설을 함수로서 정의\n",
    "@tf.function\n",
    "def hypothesis(x):\n",
    "  return w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbb9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 21. 23. 25.]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43686c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 제곱 오차를 손실 함수로서 정의\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  # 두 개의 차이값을 제곱을 해서 평균을 취한다.\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12394b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dba6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저는 경사 하강법을 사용\n",
    "# 학습률(learning rate)는 0.01을 사용\n",
    "optimizer = tf.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140e1eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0 | w의 값 : 8.2133 | b의 값 : 1.664 | cost : 1402.555542\n",
      "epoch :  10 | w의 값 : 10.4971 | b의 값 : 1.977 | cost : 1.351182\n",
      "epoch :  20 | w의 값 : 10.5047 | b의 값 :  1.93 | cost : 1.328165\n",
      "epoch :  30 | w의 값 : 10.5119 | b의 값 : 1.884 | cost : 1.306967\n",
      "epoch :  40 | w의 값 : 10.5188 | b의 값 : 1.841 | cost : 1.287436\n",
      "epoch :  50 | w의 값 : 10.5254 | b의 값 : 1.799 | cost : 1.269459\n",
      "epoch :  60 | w의 값 : 10.5318 | b의 값 : 1.759 | cost : 1.252898\n",
      "epoch :  70 | w의 값 : 10.5379 | b의 값 : 1.721 | cost : 1.237644\n",
      "epoch :  80 | w의 값 : 10.5438 | b의 값 : 1.684 | cost : 1.223598\n",
      "epoch :  90 | w의 값 : 10.5494 | b의 값 : 1.648 | cost : 1.210658\n",
      "epoch : 100 | w의 값 : 10.5548 | b의 값 : 1.614 | cost : 1.198740\n",
      "epoch : 110 | w의 값 : 10.5600 | b의 값 : 1.582 | cost : 1.187767\n",
      "epoch : 120 | w의 값 : 10.5650 | b의 값 :  1.55 | cost : 1.177665\n",
      "epoch : 130 | w의 값 : 10.5697 | b의 값 :  1.52 | cost : 1.168354\n",
      "epoch : 140 | w의 값 : 10.5743 | b의 값 : 1.492 | cost : 1.159782\n",
      "epoch : 150 | w의 값 : 10.5787 | b의 값 : 1.464 | cost : 1.151890\n",
      "epoch : 160 | w의 값 : 10.5829 | b의 값 : 1.437 | cost : 1.144619\n",
      "epoch : 170 | w의 값 : 10.5870 | b의 값 : 1.412 | cost : 1.137924\n",
      "epoch : 180 | w의 값 : 10.5909 | b의 값 : 1.387 | cost : 1.131752\n",
      "epoch : 190 | w의 값 : 10.5946 | b의 값 : 1.364 | cost : 1.126073\n",
      "epoch : 200 | w의 값 : 10.5982 | b의 값 : 1.341 | cost : 1.120843\n",
      "epoch : 210 | w의 값 : 10.6016 | b의 값 :  1.32 | cost : 1.116026\n",
      "epoch : 220 | w의 값 : 10.6049 | b의 값 : 1.299 | cost : 1.111589\n",
      "epoch : 230 | w의 값 : 10.6081 | b의 값 : 1.279 | cost : 1.107504\n",
      "epoch : 240 | w의 값 : 10.6111 | b의 값 :  1.26 | cost : 1.103736\n",
      "epoch : 250 | w의 값 : 10.6140 | b의 값 : 1.242 | cost : 1.100273\n",
      "epoch : 260 | w의 값 : 10.6168 | b의 값 : 1.224 | cost : 1.097082\n",
      "epoch : 270 | w의 값 : 10.6195 | b의 값 : 1.207 | cost : 1.094143\n",
      "epoch : 280 | w의 값 : 10.6221 | b의 값 : 1.191 | cost : 1.091434\n",
      "epoch : 290 | w의 값 : 10.6245 | b의 값 : 1.176 | cost : 1.088940\n",
      "epoch : 300 | w의 값 : 10.6269 | b의 값 : 1.161 | cost : 1.086645\n"
     ]
    }
   ],
   "source": [
    "for i in range(301):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # 현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
    "    y_pred = hypothesis(x)\n",
    "\n",
    "    # 평균 제곱 오차를 계산\n",
    "    cost = mse_loss(y_pred, y)\n",
    "\n",
    "  # 손실 함수에 대한 파라미터의 미분값 계산\n",
    "  gradients = tape.gradient(cost, [w, b])\n",
    "\n",
    "  # 파라미터 업데이트\n",
    "  optimizer.apply_gradients(zip(gradients, [w, b]))\n",
    "\n",
    "  if i % 10 == 0:\n",
    "    print(\"epoch : {:3} | w의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, w.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566d357",
   "metadata": {},
   "source": [
    "- w와 b값이 계속 업데이트 됨에 따라서 cost가 지속적으로 줄어드는 것을 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.35479  54.295143 59.608593 64.92204 ]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7c1f5",
   "metadata": {},
   "source": [
    "### 케라스로 구현하는 선형 회귀\n",
    "- 케라스로 모델을 만드는 기본적인 형식\n",
    "    - Sequential로 model이라는 이름의 모델을 만들고, 그리고 add를 통해 입력과 출력 벡터의 차원과 같은 필요한 정보들을 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c4fd8",
   "metadata": {},
   "source": [
    "model = Sequential() <br>\n",
    "model.add(keras.layers.Dense(1, input_dim=1))\n",
    "- 첫번째 인자인 1은 출력의 차원을 정의, output_dim\n",
    "- 두번째 인자인 input_dim은 입력의 차원을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d08a1d",
   "metadata": {},
   "source": [
    "- 공부한 시간을 x, 각 공부한 시간에 따른 성적을 y라고 가정\n",
    "- activation: 어떤 함수를 사용할 것인지를 의미\n",
    "    - 선형 회귀를 사용할 경우에는 linear라고 기재\n",
    "- 옵티마이저로 기본 경사 하강법 사용시 SGD 기재\n",
    "- 학습률 0.01로 정함\n",
    "- 손실함수로는 평균 제곱 오차 사용\n",
    "- 훈련 횟수 epochs 은 300으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c390b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiyoonLee\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 355ms/step - loss: 3770.4861 - mse: 3770.4861\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 465.0029 - mse: 465.0029\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 58.2869 - mse: 58.2869\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2424 - mse: 8.2424\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0836 - mse: 2.0836\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3247 - mse: 1.3247\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2302 - mse: 1.2302\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2174 - mse: 1.2174\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2147 - mse: 1.2147\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2133 - mse: 1.2133\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2120 - mse: 1.2120\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2108 - mse: 1.2108\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2095 - mse: 1.2095\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2083 - mse: 1.2083\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2071 - mse: 1.2071\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2059 - mse: 1.2059\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2047 - mse: 1.2047\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2035 - mse: 1.2035\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2023 - mse: 1.2023\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2012 - mse: 1.2012\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2000 - mse: 1.2000\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1988 - mse: 1.1988\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1977 - mse: 1.1977\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1966 - mse: 1.1966\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1955 - mse: 1.1955\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1943 - mse: 1.1943\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1932 - mse: 1.1932\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1922 - mse: 1.1922\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1911 - mse: 1.1911\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1900 - mse: 1.1900\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1889 - mse: 1.1889\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1879 - mse: 1.1879\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1868 - mse: 1.1868\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1858 - mse: 1.1858\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1847 - mse: 1.1847\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1837 - mse: 1.1837\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1827 - mse: 1.1827\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1817 - mse: 1.1817\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1807 - mse: 1.1807\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1797 - mse: 1.1797\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1787 - mse: 1.1787\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1778 - mse: 1.1778\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1768 - mse: 1.1768\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1758 - mse: 1.1758\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1749 - mse: 1.1749\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1739 - mse: 1.1739\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1730 - mse: 1.1730\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1721 - mse: 1.1721\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1712 - mse: 1.1712\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1702 - mse: 1.1702\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1693 - mse: 1.1693\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1684 - mse: 1.1684\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1675 - mse: 1.1675\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1667 - mse: 1.1667\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1658 - mse: 1.1658\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1649 - mse: 1.1649\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1641 - mse: 1.1641\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1632 - mse: 1.1632\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1624 - mse: 1.1624\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1615 - mse: 1.1615\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1607 - mse: 1.1607\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1599 - mse: 1.1599\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1590 - mse: 1.1590\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1582 - mse: 1.1582\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1574 - mse: 1.1574\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1566 - mse: 1.1566\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1558 - mse: 1.1558\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1550 - mse: 1.1550\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1543 - mse: 1.1543\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1535 - mse: 1.1535\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1527 - mse: 1.1527\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1520 - mse: 1.1520\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1512 - mse: 1.1512\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1505 - mse: 1.1505\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1497 - mse: 1.1497\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1490 - mse: 1.1490\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1482 - mse: 1.1482\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1475 - mse: 1.1475\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1468 - mse: 1.1468\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1461 - mse: 1.1461\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1454 - mse: 1.1454\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1447 - mse: 1.1447\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1440 - mse: 1.1440\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1433 - mse: 1.1433\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1426 - mse: 1.1426\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1419 - mse: 1.1419\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1413 - mse: 1.1413\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1406 - mse: 1.1406\n",
      "Epoch 89/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1399 - mse: 1.1399\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1393 - mse: 1.1393\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1386 - mse: 1.1386\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1380 - mse: 1.1380\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1373 - mse: 1.1373\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1367 - mse: 1.1367\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1361 - mse: 1.1361\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1354 - mse: 1.1354\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1348 - mse: 1.1348\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1342 - mse: 1.1342\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1336 - mse: 1.1336\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1330 - mse: 1.1330\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1324 - mse: 1.1324\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1318 - mse: 1.1318\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1312 - mse: 1.1312\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1306 - mse: 1.1306\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1301 - mse: 1.1301\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1295 - mse: 1.1295\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1289 - mse: 1.1289\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1283 - mse: 1.1283\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1278 - mse: 1.1278\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1272 - mse: 1.1272\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1267 - mse: 1.1267\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1261 - mse: 1.1261\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1256 - mse: 1.1256\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1250 - mse: 1.1250\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1245 - mse: 1.1245\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1240 - mse: 1.1240\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1235 - mse: 1.1235\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1229 - mse: 1.1229\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1224 - mse: 1.1224\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1219 - mse: 1.1219\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1214 - mse: 1.1214\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1209 - mse: 1.1209\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1204 - mse: 1.1204\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1199 - mse: 1.1199\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1194 - mse: 1.1194\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1189 - mse: 1.1189\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1184 - mse: 1.1184\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1179 - mse: 1.1179\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1175 - mse: 1.1175\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1170 - mse: 1.1170\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1165 - mse: 1.1165\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1161 - mse: 1.1161\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1156 - mse: 1.1156\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1152 - mse: 1.1152\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1147 - mse: 1.1147\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1142 - mse: 1.1142\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1138 - mse: 1.1138\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1134 - mse: 1.1134\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1129 - mse: 1.1129\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1125 - mse: 1.1125\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1121 - mse: 1.1121\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1116 - mse: 1.1116\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1112 - mse: 1.1112\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1108 - mse: 1.1108\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1104 - mse: 1.1104\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1100 - mse: 1.1100\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1095 - mse: 1.1095\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1091 - mse: 1.1091\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1087 - mse: 1.1087\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1083 - mse: 1.1083\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1079 - mse: 1.1079\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1075 - mse: 1.1075\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1071 - mse: 1.1071\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1068 - mse: 1.1068\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1064 - mse: 1.1064\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1060 - mse: 1.1060\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1056 - mse: 1.1056\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1052 - mse: 1.1052\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1049 - mse: 1.1049\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1045 - mse: 1.1045\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1041 - mse: 1.1041\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1038 - mse: 1.1038\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1034 - mse: 1.1034\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1031 - mse: 1.1031\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1027 - mse: 1.1027\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1023 - mse: 1.1023\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1020 - mse: 1.1020\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1017 - mse: 1.1017\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1013 - mse: 1.1013\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1010 - mse: 1.1010\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1006 - mse: 1.1006\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1003 - mse: 1.1003\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1000 - mse: 1.1000\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0996 - mse: 1.0996\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0993 - mse: 1.0993\n",
      "Epoch 176/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0990 - mse: 1.0990\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0987 - mse: 1.0987\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0984 - mse: 1.0984\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0980 - mse: 1.0980\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0977 - mse: 1.0977\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0974 - mse: 1.0974\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0971 - mse: 1.0971\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0968 - mse: 1.0968\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0965 - mse: 1.0965\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0962 - mse: 1.0962\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0959 - mse: 1.0959\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0956 - mse: 1.0956\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0953 - mse: 1.0953\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0950 - mse: 1.0950\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0947 - mse: 1.0947\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0944 - mse: 1.0944\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0942 - mse: 1.0942\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0939 - mse: 1.0939\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0936 - mse: 1.0936\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0933 - mse: 1.0933\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0931 - mse: 1.0931\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0928 - mse: 1.0928\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0925 - mse: 1.0925\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0922 - mse: 1.0922\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0920 - mse: 1.0920\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0917 - mse: 1.0917\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0915 - mse: 1.0915\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0912 - mse: 1.0912\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0909 - mse: 1.0909\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0907 - mse: 1.0907\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0904 - mse: 1.0904\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0902 - mse: 1.0902\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0899 - mse: 1.0899\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0897 - mse: 1.0897\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0894 - mse: 1.0894\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0892 - mse: 1.0892\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0890 - mse: 1.0890\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0887 - mse: 1.0887\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0883 - mse: 1.0883\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0880 - mse: 1.0880\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0873 - mse: 1.0873\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0871 - mse: 1.0871\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0869 - mse: 1.0869\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0867 - mse: 1.0867\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0864 - mse: 1.0864\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0862 - mse: 1.0862\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0860 - mse: 1.0860\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0858 - mse: 1.0858\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0854 - mse: 1.0854\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0850 - mse: 1.0850\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0847 - mse: 1.0847\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0845 - mse: 1.0845\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0843 - mse: 1.0843\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0841 - mse: 1.0841\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0839 - mse: 1.0839\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0837 - mse: 1.0837\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0836 - mse: 1.0836\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0834 - mse: 1.0834\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0832 - mse: 1.0832\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0830 - mse: 1.0830\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0828 - mse: 1.0828\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0826 - mse: 1.0826\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0824 - mse: 1.0824\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0822 - mse: 1.0822\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0820 - mse: 1.0820\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0819 - mse: 1.0819\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0817 - mse: 1.0817\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0815 - mse: 1.0815\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0813 - mse: 1.0813\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0812 - mse: 1.0812\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0810 - mse: 1.0810\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0808 - mse: 1.0808\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0806 - mse: 1.0806\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0805 - mse: 1.0805\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0803 - mse: 1.0803\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0801 - mse: 1.0801\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0800 - mse: 1.0800\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0798 - mse: 1.0798\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0796 - mse: 1.0796\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0795 - mse: 1.0795\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0793 - mse: 1.0793\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0791 - mse: 1.0791\n",
      "Epoch 263/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0790 - mse: 1.0790\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0788 - mse: 1.0788\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0787 - mse: 1.0787\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0785 - mse: 1.0785\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0784 - mse: 1.0784\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0782 - mse: 1.0782\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0781 - mse: 1.0781\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0779 - mse: 1.0779\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0778 - mse: 1.0778\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0776 - mse: 1.0776\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0775 - mse: 1.0775\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0773 - mse: 1.0773\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0772 - mse: 1.0772\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0771 - mse: 1.0771\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0769 - mse: 1.0769\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0768 - mse: 1.0768\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0766 - mse: 1.0766\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0765 - mse: 1.0765\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0764 - mse: 1.0764\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0762 - mse: 1.0762\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0761 - mse: 1.0761\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0760 - mse: 1.0760\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0758 - mse: 1.0758\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0757 - mse: 1.0757\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0756 - mse: 1.0756\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0754 - mse: 1.0754\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0753 - mse: 1.0753\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0752 - mse: 1.0752\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0751 - mse: 1.0751\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0749 - mse: 1.0749\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0748 - mse: 1.0748\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0747 - mse: 1.0747\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0746 - mse: 1.0746\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0744 - mse: 1.0744\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0743 - mse: 1.0743\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0742 - mse: 1.0742\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0741 - mse: 1.0741\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0740 - mse: 1.0740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d4e0d79a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 출력 y의 차원은 1. 입력 x의 차원(input_dim)은 1\n",
    "# 선형 회귀이므로 activation은 'linear'\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# sgd는 경사 하강법을 의미. 학습률(learning rate, lr)은 0.01.\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "\n",
    "# 주어진 x와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다.\n",
    "model.fit(x, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eea3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d4f383af0>,\n",
       " <matplotlib.lines.Line2D at 0x25d4f383b20>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4ebb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[102.16587]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([9.5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
